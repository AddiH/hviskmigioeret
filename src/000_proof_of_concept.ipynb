{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "import torch\n",
    "import numpy as np\n",
    "from evaluate import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_transcript = \"Tak for det, formand. Og ja, det er rigtigt, at vi nu behandler beslutningsforslag B 4 om opfølgning på visse af EU-reformgruppens anbefalinger og ændring af Færøudvalgets og Grønlandsudvalgets retsgrundlag. Hvis man starter med EU-reformgruppen, kan man nævne, at vi i Europaudvalget og i Folketinget i juni 2020 besluttede at nedsætte en ekspertgruppe, der skulle kigge på, hvordan vi arbejdede med EU-sagerne.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trimming video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_video(video_file_path, start_time, end_time, trimmed_video_path):\n",
    "    video = VideoFileClip(video_file_path).subclip(start_time, end_time)\n",
    "    video.write_videofile(trimmed_video_path, codec=\"libx264\", audio_codec=\"aac\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video ../data/video/trimmed/snip.mp4.\n",
      "MoviePy - Writing audio in snipTEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video ../data/video/trimmed/snip.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready ../data/video/trimmed/snip.mp4\n"
     ]
    }
   ],
   "source": [
    "# Path to your MP4 video file\n",
    "video_file_path = '../data/video/VOD_08-12-2022_M__de_i_salen.mp4'\n",
    "# Path for the trimmed video\n",
    "trimmed_video_path = '../data/video/trimmed/snip.mp4'\n",
    "# Path to save the extracted audio\n",
    "audio_file_path = '../data/audio/snip.wav'\n",
    "\n",
    "# Time window for trimming (in seconds)\n",
    "start_time = 60 + 47 \n",
    "end_time = 60 + 47 + 29\n",
    "\n",
    "# Trim video\n",
    "trim_video(video_file_path, start_time, end_time, trimmed_video_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in ../data/audio/snip.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "def extract_audio_from_video(video_file_path, audio_file_path):\n",
    "    video = VideoFileClip(video_file_path)\n",
    "    video.audio.write_audiofile(audio_file_path, codec='pcm_s16le')\n",
    "\n",
    "# Extract audio from trimmed video\n",
    "extract_audio_from_video(trimmed_video_path, audio_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manipulate audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in audio\n",
    "waveform, sample_rate = torchaudio.load(audio_file_path)\n",
    "\n",
    "# Convert stereo audio to mono by averaging the two channels\n",
    "waveform_mono = torch.mean(waveform, dim=0, keepdim=True)\n",
    "\n",
    "# Fix the sample rate\n",
    "resampler = T.Resample(orig_freq=sample_rate, new_freq=16000)\n",
    "waveform_resampled = resampler(waveform_mono)\n",
    "\n",
    "# save the audio\n",
    "torchaudio.save('../data/audio/resampled/snip.wav', waveform_resampled, 16000)\n",
    "\n",
    "# delete variables\n",
    "del waveform, waveform_mono, waveform_resampled, sample_rate, resampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transcribe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of waveform:  torch.Size([1, 464000])\n",
      "Sample rate:  16000\n"
     ]
    }
   ],
   "source": [
    "# load in audio\n",
    "waveform, sample_rate = torchaudio.load('../data/audio/resampled/snip.wav')\n",
    "waveform_np = waveform.squeeze().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model and processor\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-tiny\")\n",
    "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-tiny\")\n",
    "model.config.forced_decoder_ids = None\n",
    "\n",
    "# load data\n",
    "input_features = processor(waveform_np, sampling_rate=sample_rate, return_tensors=\"pt\").input_features \n",
    "\n",
    "# generate token ids\n",
    "predicted_ids = model.generate(input_features)\n",
    "# decode token ids to text\n",
    "transcription1 = processor.batch_decode(predicted_ids, skip_special_tokens=False)\n",
    "\n",
    "transcription2 = processor.batch_decode(predicted_ids, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription1: ['<|startoftranscript|><|da|><|transcribe|><|notimestamps|> Tak for det, for åmen. Jeg er det rigtig, det er beslutningst forslade b4, om opfølgelig en provisere i ureformgruppens andefalinger endringer, færdig udvalderer i konnen, så der er det skratskundlade. Og hvis man starter først med EU-reformgruppen, så er det i UFTV i juni 2000er tøb beslutet i Europa-delet og folgetændende og næsset, en ekspertgruppet, skulle klike på, at der er en vi arbejde med EU-sererne, her, hvor det er faktisk i disse måneder,<|endoftext|>']\n",
      "Transcription2: [' Tak for det, for åmen. Jeg er det rigtig, det er beslutningst forslade b4, om opfølgelig en provisere i ureformgruppens andefalinger endringer, færdig udvalderer i konnen, så der er det skratskundlade. Og hvis man starter først med EU-reformgruppen, så er det i UFTV i juni 2000er tøb beslutet i Europa-delet og folgetændende og næsset, en ekspertgruppet, skulle klike på, at der er en vi arbejde med EU-sererne, her, hvor det er faktisk i disse måneder,']\n"
     ]
    }
   ],
   "source": [
    "print(\"Transcription1:\", transcription1)\n",
    "print(\"Transcription2:\", transcription2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 100%|██████████| 11.5k/11.5k [00:00<00:00, 14.0MB/s]\n",
      "Downloading metadata: 100%|██████████| 10.1k/10.1k [00:00<00:00, 40.8MB/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import WhisperForConditionalGeneration, WhisperProcessor\n",
    "import torch\n",
    "from evaluate import load\n",
    "\n",
    "librispeech_test_clean = load_dataset(\"librispeech_asr\", \"clean\", split=\"test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-tiny\")\n",
    "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-tiny\").to(\"cuda\")\n",
    "\n",
    "def map_to_pred(batch):\n",
    "    audio = batch[\"audio\"]\n",
    "    input_features = processor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"], return_tensors=\"pt\").input_features\n",
    "    batch[\"reference\"] = processor.tokenizer._normalize(batch['text'])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        predicted_ids = model.generate(input_features.to(\"cuda\"))[0]\n",
    "    transcription = processor.decode(predicted_ids)\n",
    "    batch[\"prediction\"] = processor.tokenizer._normalize(transcription)\n",
    "    return batch\n",
    "\n",
    "result = librispeech_test_clean.map(map_to_pred)\n",
    "\n",
    "wer = load(\"wer\")\n",
    "print(100 * wer.compute(references=result[\"reference\"], predictions=result[\"prediction\"]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audio_env",
   "language": "python",
   "name": "audio_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
